"use client";

import React, { useState, useRef, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Mic, Loader2, Volume2 } from 'lucide-react';
import { cn } from '@/lib/utils';
import { useToast } from '@/hooks/use-toast';
import { GoogleGenerativeAI } from "@google/generative-ai";

const SYSTEM_INSTRUCTION = `Voc√™ √© Sofia, uma assistente de IA amig√°vel e prestativa para a galeria de arte do Circuito Carioca de Feiras Org√¢nicas.

Seu objetivo √© ajudar os usu√°rios a navegar pela galeria, encontrar informa√ß√µes sobre as feiras, os artistas, as obras e o projeto Ess√™ncia Vital.

Contexto da Galeria:
- A galeria exibe artes (imagens, v√≠deos, cartoons) criadas para as feiras org√¢nicas do Rio de Janeiro.
- O projeto √© uma iniciativa do designer Marcos Melo com o apoio da organiza√ß√£o Ess√™ncia Vital.
- As feiras acontecem em diferentes bairros: Tijuca, Graja√∫, Flamengo, Laranjeiras, Botafogo e Leme.
- A arte visa apoiar os agricultores familiares e promover a alimenta√ß√£o saud√°vel.
- Os estilos de arte incluem: "Anima√ß√µes de Agricultores", "Anima√ß√µes de Alimentos", "Anima√ß√µes de Personagens", "Fotografia", "Flyer", "Cartoon", "Story", "Datas Especiais", "Dias de Chuva".
- Personagens not√°veis incluem Inhame-Aranha, Batatman, Uverine, etc.

Suas capacidades:
1.  **Dar informa√ß√µes sobre as feiras**: "Onde e quando acontece a feira da Tijuca?", "Quais os dias da feira de Botafogo?".
2.  **Falar sobre o projeto**: "O que √© a Ess√™ncia Vital?", "Quem √© Marcos Melo?".
3.  **Ajudar a usar a galeria**: "Como posso ver s√≥ as fotografias?", "Como favorito uma arte?".
4.  **Conversa geral**: Manter um tom amig√°vel e encorajador, sempre relacionado ao universo das feiras org√¢nicas e da arte.
5.  **Filtrar a galeria**: Se o usu√°rio pedir para ver um tipo espec√≠fico de arte, uma feira, ou um personagem, voc√™ deve responder com uma a√ß√£o de filtro.

Regras de Intera√ß√£o:
- Seja sempre cordial e positiva.
- Use um emoji apropriado em cada resposta para deix√°-la mais amig√°vel (ex: üåø, ‚ú®, üñºÔ∏è, üòä).
- Mantenha as respostas concisas e diretas.
- Se n√£o souber a resposta, diga que n√£o tem essa informa√ß√£o, mas que pode ajudar com outras quest√µes sobre a galeria.
- Sempre que apropriado, incentive o usu√°rio a visitar as feiras e apoiar os agricultores.

**Regra de Filtragem (MUITO IMPORTANTE):**
- Quando um usu√°rio pedir para ver algo espec√≠fico na galeria (ex: "mostre as fotos", "quero ver os v√≠deos do Inhame-Aranha", "filtre pela feira da Tijuca"), sua resposta DEVE conter um objeto JSON especial.
- O JSON deve ter o formato: \`{"action": "filter", "filters": { "fair": "...", "style": "...", "showOnlyFavorites": "..." }}\`.
- Preencha os campos 'fair', 'style' ou 'showOnlyFavorites' com base no pedido do usu√°rio. Use os nomes exatos das feiras e estilos listados acima.
- Se o usu√°rio pedir por um personagem (ex: "Inhame-Aranha"), filtre pelo estilo "Anima√ß√µes de Personagens".
- Se o usu√°rio pedir para ver os favoritos, defina "showOnlyFavorites" como true.
- Se o usu√°rio pedir para limpar os filtros, envie \`{"action": "filter", "filters": { "fair": "", "style": "", "showOnlyFavorites": false }}\`.
- **Sua resposta final deve ser o texto amig√°vel seguido da tag <|JSON|> e o objeto JSON.**

Exemplos de Resposta de Filtragem:
Usu√°rio: "Quero ver apenas as fotografias"
Sofia: "Claro! Filtrando para mostrar apenas as fotografias. üñºÔ∏è<|JSON|>{\\"action\\": \\"filter\\", \\"filters\\": {\\"style\\": \\"Fotografia\\"}}"

Usu√°rio: "Mostre os v√≠deos do Inhame-Aranha"
Sofia: "Boa escolha! Preparando a galeria para mostrar as anima√ß√µes de personagens, incluindo nosso her√≥i Inhame-Aranha. üï∏Ô∏è<|JSON|>{\\"action\\": \\"filter\\", \\"filters\\": {\\"style\\": \\"Anima√ß√µes de Personagens\\"}}"

Usu√°rio: "Quais artes s√£o da feira de Botafogo?"
Sofia: "Exibindo agora todas as artes da feira de Botafogo para voc√™! ‚ú®<|JSON|>{\\"action\\": \\"filter\\", \\"filters\\": {\\"fair\\": \\"Botafogo\\"}}"

Usu√°rio: "Limpar todos os filtros"
Sofia: "Ok, limpando os filtros e mostrando toda a galeria novamente. üòä<|JSON|>{\\"action\\": \\"filter\\", \\"filters\\": {\\"fair\\": \\"\\", \\"style\\": \\"\\", \\"showOnlyFavorites\\": false}}"
`;

// A chave de API est√° agora diretamente no c√≥digo para garantir o funcionamento.
const API_KEY = "AIzaSyDaA76diGNYghIXd2ASpLLRFw3QN6LyeUo";

let genAI: GoogleGenerativeAI | null = null;
if (API_KEY) {
  genAI = new GoogleGenerativeAI(API_KEY);
} else {
  console.error("Chave de API do Gemini n√£o encontrada.");
}

const model = genAI?.getGenerativeModel({
  model: "gemini-1.5-flash",
  systemInstruction: SYSTEM_INSTRUCTION,
});


type AssistantState = 'idle' | 'listening' | 'processing' | 'speaking';

type AssistantButtonProps = {
  onApplyFilters: (filters: any) => void;
};

interface CustomWindow extends Window {
  SpeechRecognition: typeof SpeechRecognition;
  webkitSpeechRecognition: typeof SpeechRecognition;
}
declare const window: CustomWindow;

export function AssistantButton({ onApplyFilters }: AssistantButtonProps) {
  const [state, setState] = useState<AssistantState>('idle');
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const { toast } = useToast();
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const [voices, setVoices] = useState<SpeechSynthesisVoice[]>([]);

  useEffect(() => {
    if (typeof window === 'undefined' || !window.speechSynthesis) return;

    const loadVoices = () => {
      const availableVoices = window.speechSynthesis.getVoices();
      if (availableVoices.length > 0) {
        setVoices(availableVoices);
      }
    };

    // As vozes s√£o carregadas de forma ass√≠ncrona
    window.speechSynthesis.onvoiceschanged = loadVoices;
    loadVoices(); // Tenta carregar imediatamente tamb√©m

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (SpeechRecognition) {
      const recognition = new SpeechRecognition();
      recognition.lang = 'pt-BR';
      recognition.interimResults = false;
      recognition.continuous = false;

      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        if (transcript) {
          handleSendMessage(transcript);
        }
      };

      recognition.onend = () => {
        setState(prevState => (prevState === 'listening' ? 'idle' : prevState));
      };
      
      recognition.onerror = (event) => {
        console.error("Erro no reconhecimento de voz:", event.error);
        if (event.error === 'no-speech') {
            toast({ title: "Assistente", description: "N√£o ouvi nada. Tente novamente." });
        } else {
            toast({ title: "Erro de Voz", description: `N√£o consegui captar sua voz: ${event.error}`, variant: 'destructive' });
        }
        setState('idle');
      };
      
      recognitionRef.current = recognition;
    } else {
        console.error("Speech Recognition API n√£o √© suportada neste navegador.");
    }

    return () => {
      recognitionRef.current?.abort();
      window.speechSynthesis?.cancel();
    };
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  const handleMouseDown = () => {
    if (state !== 'idle') return;
    if (recognitionRef.current) {
      window.speechSynthesis?.cancel(); 
      setState('listening');
      try {
        recognitionRef.current.start();
      } catch(e) {
        console.error("N√£o foi poss√≠vel iniciar a escuta:", e);
        toast({ title: "Erro", description: "N√£o foi poss√≠vel iniciar a grava√ß√£o.", variant: 'destructive' });
        setState('idle');
      }
    }
  };

  const handleMouseUp = () => {
    if (state !== 'listening') return;
    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop();
      } catch(e) {
        console.error("N√£o foi poss√≠vel parar a escuta:", e);
        setState('idle');
      }
    }
  };
  
  const speak = async (text: string) => {
    if (typeof window === 'undefined' || !window.speechSynthesis) {
        console.error('S√≠ntese de voz n√£o √© suportada neste navegador.');
        setState('idle');
        return;
    }

    const startSpeaking = () => {
      window.speechSynthesis.cancel();
    
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'pt-BR';
      utterance.rate = 1.1;

      // Agora usamos as vozes do estado, que sabemos que est√£o carregadas
      const brVoice = voices.find(voice => voice.lang === 'pt-BR');
      if (brVoice) {
          utterance.voice = brVoice;
      } else {
        console.warn("Nenhuma voz em 'pt-BR' encontrada. Usando a voz padr√£o do navegador.");
      }

      utterance.onstart = () => setState('speaking');
      utterance.onend = () => setState('idle');
      utterance.onerror = (e) => {
          console.error("Erro na s√≠ntese de voz:", e);
          toast({ title: "Erro de √Åudio", description: "N√£o consegui reproduzir a resposta.", variant: 'destructive' });
          setState('idle');
      };
      
      window.speechSynthesis.speak(utterance);
    };

    // Se as vozes ainda n√£o foram carregadas, esperamos.
    if (voices.length === 0 && window.speechSynthesis.getVoices().length === 0) {
      // Define um timeout caso o evento onvoiceschanged n√£o dispare
      const voiceTimeout = setTimeout(() => {
        console.warn("Timeout ao esperar pelas vozes. Tentando falar com a voz padr√£o.");
        startSpeaking();
      }, 1000); // Espera 1 segundo

      window.speechSynthesis.onvoiceschanged = () => {
        clearTimeout(voiceTimeout);
        setVoices(window.speechSynthesis.getVoices()); // Atualiza o estado
        startSpeaking();
      };
    } else {
      if (voices.length === 0) setVoices(window.speechSynthesis.getVoices());
      startSpeaking();
    }
  };

  const handleSendMessage = async (messageToSend: string) => {
    if (!messageToSend.trim()) {
      setState('idle');
      return;
    }
    
    if (!API_KEY || !model) {
      const errorMessage = "Desculpe, a minha configura√ß√£o de IA n√£o est√° completa. Por favor, verifique a chave de API no ambiente.";
      console.error(errorMessage);
      speak(errorMessage);
      setState('idle');
      return;
    }

    setState('processing');

    try {
      const chat = model.startChat({ history: [] });
      const result = await chat.sendMessage(messageToSend);
      const response = await result.response;
      let text = response.text();

      let filters = null;
      if (text.includes('<|JSON|>')) {
        const parts = text.split('<|JSON|>');
        text = parts[0];
        try {
          const jsonPart = parts[1];
          const parsedJson = JSON.parse(jsonPart);
          if (parsedJson.action === 'filter') {
            filters = parsedJson.filters;
          }
        } catch (e) {
          console.error("Erro ao parsear JSON da resposta da IA:", e);
        }
      }
      
      speak(text);

      if (filters) {
        onApplyFilters(filters);
      }

    } catch (error: any) {
      console.error("Erro ao chamar a API do Gemini:", error);
      const errorMessage = "Desculpe, n√£o consegui me conectar. Por favor, verifique se a sua chave de API √© v√°lida e tente novamente.";
      speak(errorMessage);
      setState('idle');
    }
  };


  const getButtonIcon = () => {
    const iconSize = "w-8 h-8";
    switch (state) {
      case 'listening':
        return <Mic className={cn(iconSize, "text-accent-foreground")} />;
      case 'processing':
        return <Loader2 className={cn(iconSize, "text-accent-foreground animate-spin")} />;
      case 'speaking':
        return <Volume2 className={cn(iconSize, "text-accent-foreground")} />;
      case 'idle':
      default:
        return <Mic className={cn(iconSize, "text-accent-foreground")} />;
    }
  };
  
  const getButtonClass = () => {
    switch (state) {
      case 'listening':
        return "bg-red-600 hover:bg-red-700 scale-110";
      case 'processing':
        return "bg-accent/80 cursor-not-allowed";
      case 'speaking':
         return "bg-blue-600 hover:bg-blue-700";
      case 'idle':
      default:
        return "bg-accent hover:bg-accent/90";
    }
  }

  return (
      <Button
        onMouseDown={handleMouseDown}
        onMouseUp={handleMouseUp}
        onTouchStart={handleMouseDown}
        onTouchEnd={handleMouseUp}
        disabled={state === 'processing' || !recognitionRef.current || !API_KEY}
        className={cn(
          "fixed bottom-6 right-6 w-16 h-16 rounded-full shadow-lg flex items-center justify-center transition-all duration-300 ease-in-out touch-manipulation",
          getButtonClass()
        )}
      >
        {getButtonIcon()}
      </Button>
  );
}
